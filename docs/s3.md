# MSI Second Tier ("tier 2") Storage & S3 Bucket Interface
Second tier storage is used for storing data and files that you don't need readily accessible on tier 1. Each user has 120 TB of space, which is why it is preferred to store data here as opposed to tier 1. In order to gain access to an S3 bucket, contact someone who does have access so that they can update the s3_policy. 

For a comprehensive introduction to s3, see [this tutorial video](https://drive.google.com/drive/folders/1Oz3i5lbld5VmXGdhWagOMWYOIJmgrJA4) (recorded as part of the Data Processing Workshop hosted for undergraduate research assistants). It is encouraged to watch this tutorial prior to your first time using s3 commands. Note that after you run workbench commands, make sure to `module rm workbench` prior to doing any `s3cmd` commands.


## s3 Basic Commands

**Please see [s3cmd usage page](https://s3tools.org/usage)**

Additional notes/tips:
 - You are no longer allowed to have to an underscore or uppercase letter in your bucket name. MSI might still let you create a bucket with an uppercase, but it can cause issues with other programs that interact with s3 buckets. As a guideline, follow the example bucket name ("s3://bucket-name/") above. For more information, [visit this link](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html).
 - Remember to use the `--recursive` flag when syncing folders to/from s3
 - If you're re-running a pipeline/process and you only want the new outputs to be in the directory that you're syncing to, include the `--delete-removed` flag to your sync command to remove files that are present in the destination path but aren't present in the source path. *USE WITH CAUTION*
 - For commands such as `du` and `ls` on large buckets, we recommend using [s5cmd client](#s5cmd-client)
 - To view your s3 credentials and disk usage: `s3info -u x500`

## Setting a policy on s3   

78. Setting an S3 policy on MSI:

    - Must use this path for your `~/.bashrc` to be able to use the set_s3policy command: `export PATH=/home/dhp/public/storage/s3policy_bin/:$PATH`

        - To open your `~/.bashrc` and modify it, use `emacs ~/.bashrc &`

        - For this change to take effect, close out of your terminal/OpenOnDemand session and reenter 

    - To check who already has access to the bucket, run: `/home/faird/shared/code/internal/utilities/MSI-utilities/s3_get_x500/get_x500.sh s3://bucket_name/`

        - Note that this won't include you, so don't forget to include yourself, especially if it isn't your bucket (you can revoke your own access).

        - The CDNI google drive has a Lab Data Locations sheet with the locations and owners of s3 buckets

    - Then use this command to set the s3 policy, **DO NOT** include the s3:// prefix in the command: 

        `set_s3policy x500_1,x500_2,etc bucket_name FULL` 

    - **IMPORTANT: every time you set a policy you need to list EVERYONE that needs access. You CANNOT just list that one person's x500 or only that one person will have access to the bucket! (Along with the bucket owner)**

20. Instructions to the manual method of setting an s3 policy on MSI can be found at [this link](https://www.msi.umn.edu/support/faq/how-do-i-use-s3-buckets-share-data-tier-2-storage-other-users). An example policy file that gives full access to the s3 bucket  “bucket_name” is as follows:

    ![Example s3 policy](img/s3-policy.png)


## Setting up a .s3cfg

79. Setting up a .s3cfg file: 

    - Open a new terminal in MSI and create a file named `.s3cfg-RANDOM` in your home directory

        * Can't just be `.s3cfg`, name it something identifiable 

    - Run `s3cmd -c ~/.s3cfg-RANDOM --configure` and provide your Access Key ID and Secret Access Key when prompted

    - You shouldn't have to make any changes to the file unless the s3 bucket is hosted by something different than *s3.amazonaws.com*  

    - Test your access through an `ls` command - the `s3cmd -c ~/.s3cfg-RANDOM` will have to be part of every command you run to access the buckets that require the credentials you provided.

## s3 access with Cyberduck 
Resource: [View your MSI S3 credentials (login required)](https://www.msi.umn.edu/content/s3-credentials) 

Read: [Cyberduck S3 documentation](https://docs.cyberduck.io/protocols/s3/)

[Cyberduck](https://cyberduck.io/) is a cloud storage browser for Windows and macOS devices, which can be used to access s3 storage from your local machine. To access MSI Tier 2 storage in Cyberduck, connect to *s3.msi.umn.edu* using your s3 credentials, which can be retrieved from the link at the top of this subsection or by running `s3info` in your MSI terminal. 

To log in for the first time, follow the following steps:

- Click "Open Connection" in the top left corner of the screen

- Select "Amazon s3" from the drop down menu

- Type in *s3.msi.umn.edu* for the server 

- Enter you access and secret keys 

- Click "Connect"

## s5cmd client

Read: [s5cmd GitHub](https://github.com/peak/s5cmd)

The **s5cmd** client is installed on MSI at `/home/faird/shared/code/external/utilities/s5cmd/s5cmd`.

**s5cmd** is an alternative S3 client that performs much faster on MSI than s3cmd for certain operations (roughly 10x-100x faster for `du` and `ls`). Its usage is similar to s3cmd, but does require the additional argument  `--endpoint-url https://s3.msi.umn.edu` so that commands are directed to MSI's S3 (Tier 2) and not AWS S3.

Example using `du -H`: `/home/faird/shared/code/external/utilities/s5cmd/s5cmd --endpoint-url https://s3.msi.umn.edu du -H s3://MY_BUCKET/*`

Some additional setup is required to use s5cmd:

- run `s5cmd` once with `--install-completion`, and follow the instructions to add the code needed for path completion to your `~/.bashrc`
- export the environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` -- this can be also be done in your `~/.bashrc`, by adding the following:
```
export AWS_SECRET_ACCESS_KEY=$(s3info | grep Secret | awk '{ print $NF }' )
export AWS_ACCESS_KEY_ID=$(s3info | grep Access | awk '{ print $NF }' )
```

Currently, s5cmd cannot resume interrupted file transfers (upload or download), so it is advisable **not** to use it over s3cmd for file transfers.


For questions, suggestions, or to note any errors, post an issue on our [Github](https://github.com/DCAN-Labs/cdni-brain/issues).
